name: Validate Metadata Migration (Dry Run)

on:
  workflow_dispatch:
    inputs:
      entities_file:
        description: 'Path to JSON file with exported entities (relative to repo root)'
        required: true
        type: string
        default: 'metadata-manager/dev/editable_entities/exported_entities.json'
      target_environment:
        description: 'Target environment name'
        required: true
        default: 'staging'
        type: choice
        options:
          - dev
          - staging
          - prod
  pull_request:
    paths:
      - 'metadata-migration/**'
      - 'metadata-manager/*/editable_entities/**'
      - 'scripts/process_metadata_migration.py'

env:
  PYTHONPATH: ${{ github.workspace }}

jobs:
  detect-migration-files:
    runs-on: ubuntu-latest
    outputs:
      has_migration_files: ${{ steps.check.outputs.has_files }}
      migration_files: ${{ steps.check.outputs.files }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check for migration files
        id: check
        run: |
          # Check for migration files
          migration_files=""
          has_files="false"
          
          # Manual trigger
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            if [ -f "${{ github.event.inputs.entities_file }}" ]; then
              migration_files="${{ github.event.inputs.entities_file }}"
              has_files="true"
            fi
          else
            # PR trigger - look for migration files in the PR
            # Check both metadata-migration directory and environment editable_entities directories
            migration_files=""
            
            if [ -d "metadata-migration" ]; then
              migration_files=$(find metadata-migration -name "*.json" -type f | head -5 | tr '\n' ',' | sed 's/,$//')
            fi
            
            # Also check environment editable_entities directories
            env_migration_files=$(find metadata-manager/*/editable_entities -name "*.json" -type f 2>/dev/null | head -5 | tr '\n' ',' | sed 's/,$//')
            
            if [ -n "$migration_files" ] && [ -n "$env_migration_files" ]; then
              migration_files="$migration_files,$env_migration_files"
            elif [ -n "$env_migration_files" ]; then
              migration_files="$env_migration_files"
            fi
            
            if [ -n "$migration_files" ]; then
              has_files="true"
            fi
          fi
          
          echo "has_files=$has_files" >> $GITHUB_OUTPUT
          echo "files=$migration_files" >> $GITHUB_OUTPUT
          
          echo "üîç Migration files detected: $has_files"
          echo "üìÅ Files: $migration_files"

  validate-structure:
    runs-on: ubuntu-latest
    needs: detect-migration-files
    if: needs.detect-migration-files.outputs.has_migration_files == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-web.txt

      - name: Validate JSON structure
        run: |
          echo "üîç Validating JSON structure of migration files..."
          
          # Get the entities file
          ENTITIES_FILE=""
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            ENTITIES_FILE="${{ github.event.inputs.entities_file }}"
          else
            # Use first migration file found
            ENTITIES_FILE=$(echo "${{ needs.detect-migration-files.outputs.migration_files }}" | cut -d',' -f1)
          fi
          
          if [ ! -f "$ENTITIES_FILE" ]; then
            echo "‚ùå Migration file not found: $ENTITIES_FILE"
            exit 1
          fi
          
          echo "üìÑ Validating: $ENTITIES_FILE"
          
          python << EOF
          import json
          import sys
          
          def validate_entity_structure(entity, entity_idx):
              """Validate individual entity structure"""
              errors = []
              
              # Required fields
              if not entity.get('urn'):
                  errors.append(f"Entity {entity_idx}: Missing 'urn' field")
              if not entity.get('type'):
                  errors.append(f"Entity {entity_idx}: Missing 'type' field")
              
              # Check for metadata to migrate
              has_metadata = False
              metadata_types = []
              
              if entity.get('tags', {}).get('tags'):
                  has_metadata = True
                  metadata_types.append('tags')
              
              if entity.get('glossaryTerms', {}).get('terms'):
                  has_metadata = True
                  metadata_types.append('glossaryTerms')
              
              if entity.get('domain', {}).get('urn'):
                  has_metadata = True
                  metadata_types.append('domain')
              
              if entity.get('structuredProperties', {}).get('properties'):
                  has_metadata = True
                  metadata_types.append('structuredProperties')
              
              # Check schema field metadata
              if entity.get('schemaMetadata', {}).get('fields'):
                  for field in entity['schemaMetadata']['fields']:
                      if (field.get('tags', {}).get('tags') or 
                          field.get('glossaryTerms', {}).get('terms')):
                          has_metadata = True
                          metadata_types.append('schemaFieldMetadata')
                          break
              
              if not has_metadata:
                  errors.append(f"Entity {entity_idx}: No metadata to migrate (tags, glossaryTerms, domain, structuredProperties, or field metadata)")
              
              return errors, metadata_types
          
          try:
              with open('$ENTITIES_FILE', 'r') as f:
                  data = json.load(f)
              
              # Handle different export formats
              if isinstance(data, dict):
                  if 'entities' in data:
                      entities = data['entities']
                  elif 'export_data' in data:
                      entities = data['export_data']
                  else:
                      entities = [data]
              else:
                  entities = data
              
              print(f"‚úÖ Valid JSON with {len(entities)} entities")
              
              # Validate structure
              all_errors = []
              metadata_summary = {}
              
              for i, entity in enumerate(entities):
                  errors, metadata_types = validate_entity_structure(entity, i + 1)
                  all_errors.extend(errors)
                  
                  for meta_type in metadata_types:
                      metadata_summary[meta_type] = metadata_summary.get(meta_type, 0) + 1
              
              if all_errors:
                  print(f"‚ùå Found {len(all_errors)} validation errors:")
                  for error in all_errors[:10]:  # Show first 10 errors
                      print(f"   ‚Ä¢ {error}")
                  if len(all_errors) > 10:
                      print(f"   ... and {len(all_errors) - 10} more errors")
                  sys.exit(1)
              
              print("‚úÖ All entities have valid structure")
              print(f"üìä Metadata summary:")
              for meta_type, count in metadata_summary.items():
                  print(f"   ‚Ä¢ {meta_type}: {count} entities")
              
          except json.JSONDecodeError as e:
              print(f"‚ùå Invalid JSON format: {e}")
              sys.exit(1)
          except Exception as e:
              print(f"‚ùå Validation failed: {e}")
              sys.exit(1)
          EOF

  validate-urns:
    runs-on: ubuntu-latest
    needs: [detect-migration-files, validate-structure]
    if: needs.detect-migration-files.outputs.has_migration_files == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Validate URN formats
        run: |
          echo "üîç Validating URN formats..."
          
          # Get the entities file
          ENTITIES_FILE=""
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            ENTITIES_FILE="${{ github.event.inputs.entities_file }}"
          else
            ENTITIES_FILE=$(echo "${{ needs.detect-migration-files.outputs.migration_files }}" | cut -d',' -f1)
          fi
          
          python << EOF
          import json
          import re
          import sys
          
          def validate_urn_format(urn, context=""):
              """Validate DataHub URN format"""
              if not urn.startswith('urn:li:'):
                  return f"Invalid URN format (must start with 'urn:li:'): {urn} {context}"
              
              # Basic pattern check
              urn_pattern = r'^urn:li:[a-zA-Z]+:.*'
              if not re.match(urn_pattern, urn):
                  return f"Invalid URN pattern: {urn} {context}"
              
              # Check for obvious issues
              if ',,' in urn:
                  return f"Double commas in URN: {urn} {context}"
              
              if urn.endswith(','):
                  return f"URN ends with comma: {urn} {context}"
              
              return None
          
          try:
              with open('$ENTITIES_FILE', 'r') as f:
                  data = json.load(f)
              
              if isinstance(data, dict):
                  entities = data.get('entities', data.get('export_data', [data]))
              else:
                  entities = data
              
              urn_errors = []
              unique_urns = set()
              duplicate_urns = set()
              
              for i, entity in enumerate(entities):
                  entity_urn = entity.get('urn', '')
                  
                  if entity_urn:
                      # Check format
                      error = validate_urn_format(entity_urn, f"(entity {i+1})")
                      if error:
                          urn_errors.append(error)
                      
                      # Check for duplicates
                      if entity_urn in unique_urns:
                          duplicate_urns.add(entity_urn)
                      else:
                          unique_urns.add(entity_urn)
                      
                      # Validate related URNs
                      if entity.get('tags', {}).get('tags'):
                          for tag in entity['tags']['tags']:
                              tag_urn = tag.get('tag', {}).get('urn', '')
                              if tag_urn:
                                  error = validate_urn_format(tag_urn, f"(tag in entity {i+1})")
                                  if error:
                                      urn_errors.append(error)
                      
                      # Validate glossary term URNs
                      if entity.get('glossaryTerms', {}).get('terms'):
                          for term in entity['glossaryTerms']['terms']:
                              term_urn = term.get('term', {}).get('urn', '')
                              if term_urn:
                                  error = validate_urn_format(term_urn, f"(glossary term in entity {i+1})")
                                  if error:
                                      urn_errors.append(error)
                      
                      # Validate domain URN
                      if entity.get('domain', {}).get('urn'):
                          domain_urn = entity['domain']['urn']
                          error = validate_urn_format(domain_urn, f"(domain in entity {i+1})")
                          if error:
                              urn_errors.append(error)
                      
                      # Validate structured property URNs
                      if entity.get('structuredProperties', {}).get('properties'):
                          for prop in entity['structuredProperties']['properties']:
                              prop_urn = prop.get('structuredProperty', {}).get('urn', '')
                              if prop_urn:
                                  error = validate_urn_format(prop_urn, f"(structured property in entity {i+1})")
                                  if error:
                                      urn_errors.append(error)
              
              # Report results
              if urn_errors:
                  print(f"‚ùå Found {len(urn_errors)} URN format errors:")
                  for error in urn_errors[:15]:
                      print(f"   ‚Ä¢ {error}")
                  if len(urn_errors) > 15:
                      print(f"   ... and {len(urn_errors) - 15} more errors")
                  sys.exit(1)
              
              if duplicate_urns:
                  print(f"‚ö†Ô∏è  Found {len(duplicate_urns)} duplicate entity URNs:")
                  for dup_urn in list(duplicate_urns)[:5]:
                      print(f"   ‚Ä¢ {dup_urn}")
                  if len(duplicate_urns) > 5:
                      print(f"   ... and {len(duplicate_urns) - 5} more duplicates")
                  print("Note: Duplicates will be processed multiple times")
              
              print("‚úÖ All URNs have valid format")
              print(f"üìä Unique entity URNs: {len(unique_urns)}")
              
          except Exception as e:
              print(f"‚ùå URN validation failed: {e}")
              sys.exit(1)
          EOF

  dry-run-migration:
    runs-on: ubuntu-latest
    needs: [detect-migration-files, validate-structure, validate-urns]
    if: needs.detect-migration-files.outputs.has_migration_files == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-web.txt

      - name: Run dry-run migration
        run: |
          echo "üß™ Running dry-run metadata migration..."
          
          # Get the entities file and target environment
          ENTITIES_FILE=""
          TARGET_ENV="staging"
          
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            ENTITIES_FILE="${{ github.event.inputs.entities_file }}"
            TARGET_ENV="${{ github.event.inputs.target_environment }}"
          else
            ENTITIES_FILE=$(echo "${{ needs.detect-migration-files.outputs.migration_files }}" | cut -d',' -f1)
          fi
          
          # Create output directory
          mkdir -p validation-output
          
          # Look for mutations file
          MUTATIONS_ARG=""
          if [ -f "params/environments/$TARGET_ENV/mutations.json" ]; then
            MUTATIONS_ARG="--mutations-file params/environments/$TARGET_ENV/mutations.json"
            echo "‚úÖ Found mutations file for $TARGET_ENV"
          elif [ -f "web_ui/environments/${TARGET_ENV}_mutations.json" ]; then
            MUTATIONS_ARG="--mutations-file web_ui/environments/${TARGET_ENV}_mutations.json"
            echo "‚úÖ Found mutations file for $TARGET_ENV"
          else
            echo "‚ö†Ô∏è  No mutations file found for $TARGET_ENV"
          fi
          
          # Run the migration script in dry-run mode
          python scripts/process_metadata_migration.py \
            --input "$ENTITIES_FILE" \
            --target-env "$TARGET_ENV" \
            $MUTATIONS_ARG \
            --output-dir "validation-output" \
            --dry-run \
            --verbose

      - name: Upload validation results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: migration-validation-${{ github.run_number }}
          path: validation-output/
          retention-days: 7

      - name: Create validation summary
        if: always()
        run: |
          echo "## üß™ Metadata Migration Validation Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Validation Mode**: Dry Run" >> $GITHUB_STEP_SUMMARY
          echo "**Target Environment**: ${{ github.event.inputs.target_environment || 'staging' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count generated MCPs
          if [ -d "validation-output" ]; then
            mcp_count=$(find validation-output -name "*.json" | wc -l)
            echo "**Generated MCPs**: $mcp_count" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ $mcp_count -gt 0 ]; then
              echo "### Sample MCPs" >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              find validation-output -name "*.json" | head -3 | xargs ls -la
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üìé **Validation artifacts** are available for download above." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ **Next Steps**: If validation passes, you can run the live migration using the 'Migrate Metadata Between Environments' workflow." >> $GITHUB_STEP_SUMMARY

  comment-pr:
    runs-on: ubuntu-latest
    needs: [detect-migration-files, dry-run-migration]
    if: github.event_name == 'pull_request' && needs.detect-migration-files.outputs.has_migration_files == 'true'
    steps:
      - name: Comment on PR
        uses: actions/github-script@v7
        with:
          script: |
            const comment = `## üß™ Metadata Migration Validation
            
            This PR contains metadata migration files. The validation workflow has completed:
            
            - ‚úÖ JSON structure validation
            - ‚úÖ URN format validation  
            - ‚úÖ Dry-run migration test
            
            **Files processed**: ${{ needs.detect-migration-files.outputs.migration_files }}
            
            üìé **Validation artifacts** are available in the workflow run.
            
            **To perform the actual migration**:
            1. Merge this PR
            2. Run the "Migrate Metadata Between Environments" workflow
            3. Select the appropriate source and target environments
            4. Choose whether to run in dry-run mode first
            
            ‚ö†Ô∏è **Important**: Always test with dry-run mode first before running live migrations.`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            }); 