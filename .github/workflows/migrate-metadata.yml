name: Migrate Metadata Between Environments

on:
  workflow_dispatch:
    inputs:
      entities_file:
        description: 'Path to JSON file with exported entities (relative to repo root)'
        required: true
        type: string
        default: 'metadata-manager/dev/editable_entities/exported_entities_with_mutations.json'
      source_environment:
        description: 'Source environment name'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod
      target_environment:
        description: 'Target environment name'
        required: true
        default: 'staging'
        type: choice
        options:
          - dev
          - staging
          - prod
      dry_run:
        description: 'Perform dry run (validate only, do not emit MCPs)'
        required: false
        default: true
        type: boolean
      include_field_metadata:
        description: 'Include schema field tags and glossary terms'
        required: false
        default: true
        type: boolean

env:
  PYTHONPATH: ${{ github.workspace }}

jobs:
  validate-inputs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Validate inputs
        run: |
          echo "ğŸ” Validating workflow inputs..."
          
          # Check that source and target environments are different
          if [ "${{ github.event.inputs.source_environment }}" = "${{ github.event.inputs.target_environment }}" ]; then
            echo "âŒ Source and target environments cannot be the same"
            exit 1
          fi
          
          # Check if entities file exists
          if [ ! -f "${{ github.event.inputs.entities_file }}" ]; then
            echo "âŒ Entities file not found: ${{ github.event.inputs.entities_file }}"
            echo "Please upload your exported entities JSON file to the repository first"
            exit 1
          fi
          
          # Validate JSON format
          if ! python -m json.tool "${{ github.event.inputs.entities_file }}" > /dev/null 2>&1; then
            echo "âŒ Invalid JSON format in entities file"
            exit 1
          fi
          
          echo "âœ… All inputs validated successfully"
          echo "ğŸ“‚ Entities file: ${{ github.event.inputs.entities_file }}"
          echo "ğŸ”„ Migration: ${{ github.event.inputs.source_environment }} â†’ ${{ github.event.inputs.target_environment }}"
          echo "ğŸ§ª Dry run: ${{ github.event.inputs.dry_run }}"

  fetch-target-entities:
    runs-on: ubuntu-latest
    needs: validate-inputs
    if: ${{ github.event.inputs.dry_run == 'false' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-web.txt

      - name: Load environment configuration
        run: |
          # Load target environment configuration
          ENV_FILE="params/environments/${{ github.event.inputs.target_environment }}"
          if [ -d "$ENV_FILE" ]; then
            echo "ğŸ“‹ Loading environment configuration for ${{ github.event.inputs.target_environment }}"
            find "$ENV_FILE" -name "*.yml" -o -name "*.yaml" | head -5
          else
            echo "âš ï¸  No specific environment configuration found for ${{ github.event.inputs.target_environment }}"
          fi

      - name: Test DataHub connection
        env:
          DATAHUB_GMS_URL: ${{ secrets[format('DATAHUB_GMS_URL_{0}', github.event.inputs.target_environment)] }}
          DATAHUB_GMS_TOKEN: ${{ secrets[format('DATAHUB_GMS_TOKEN_{0}', github.event.inputs.target_environment)] }}
        run: |
          echo "ğŸ”— Testing connection to target DataHub environment..."
          python -c "
          import os
          from utils.datahub_api import DataHubAPIClient
          
          try:
              client = DataHubAPIClient()
              # Test basic connectivity
              print('âœ… Successfully connected to DataHub')
          except Exception as e:
              print(f'âŒ Failed to connect to DataHub: {e}')
              exit(1)
          "

  analyze-entities:
    runs-on: ubuntu-latest
    needs: validate-inputs
    outputs:
      platforms: ${{ steps.analysis.outputs.platforms }}
      entity_types: ${{ steps.analysis.outputs.entity_types }}
      entity_count: ${{ steps.analysis.outputs.entity_count }}
      has_mutations: ${{ steps.analysis.outputs.has_mutations }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Analyze exported entities
        id: analysis
        run: |
          echo "ğŸ” Analyzing exported entities..."
          
          python << EOF
          import json
          import sys
          from collections import Counter
          
          # Load entities file
          try:
              with open('${{ github.event.inputs.entities_file }}', 'r') as f:
                  data = json.load(f)
              
              print(f"ğŸ“Š Loaded JSON data type: {type(data)}")
              if isinstance(data, dict):
                  print(f"ğŸ“Š Dictionary keys: {list(data.keys())}")
              elif isinstance(data, list):
                  print(f"ğŸ“Š List length: {len(data)}")
                  if data:
                      print(f"ğŸ“Š First item type: {type(data[0])}")
              else:
                  print(f"ğŸ“Š Raw data: {str(data)[:200]}...")
          
              # Handle different export formats
              if isinstance(data, dict):
                  if 'entities' in data:
                      entities = data['entities']
                  elif 'export_data' in data:
                      entities = data['export_data']
                  else:
                      entities = [data]
              elif isinstance(data, list):
                  entities = data
              else:
                  print(f"âš ï¸ Unexpected data format: {type(data)}")
                  entities = []
              
              # Ensure entities is a list
              if not isinstance(entities, list):
                  print(f"âš ï¸ Entities is not a list: {type(entities)}")
                  entities = []
              
              # Filter out None values
              entities = [e for e in entities if e is not None]
              
              if not entities:
                  print("âš ï¸ No valid entities found in file")
                  sys.exit(1)
              
              print(f"ğŸ“Š Processing {len(entities)} entities")
              if entities:
                  print(f"ğŸ“Š First entity type: {type(entities[0])}")
                  if isinstance(entities[0], dict):
                      print(f"ğŸ“Š First entity keys: {list(entities[0].keys())}")
              
              # Analyze entities
              platforms = []
              entity_types = []
              has_metadata = False
              skipped_entities = 0
              
              for i, entity in enumerate(entities):
                  # Skip None or invalid entities
                  if not entity or not isinstance(entity, dict):
                      skipped_entities += 1
                      print(f"âš ï¸ Skipping entity {i}: {type(entity)} - {str(entity)[:100]}")
                      continue
                  
                  # Platform
                  platform_info = entity.get('platform', {})
                  if platform_info and isinstance(platform_info, dict) and platform_info.get('name'):
                      platforms.append(platform_info['name'])
                  
                  # Entity type
                  entity_type = entity.get('type')
                  if entity_type:
                      entity_types.append(entity_type)
                  
                  # Check for metadata to migrate
                  tags = entity.get('tags', {})
                  glossary_terms = entity.get('glossaryTerms', {})
                  domain = entity.get('domain', {})
                  structured_props = entity.get('structuredProperties', {})
                  
                  if ((tags and isinstance(tags, dict) and tags.get('tags')) or 
                      (glossary_terms and isinstance(glossary_terms, dict) and glossary_terms.get('terms')) or
                      (domain and isinstance(domain, dict) and domain.get('urn')) or
                      (structured_props and isinstance(structured_props, dict) and structured_props.get('properties'))):
                      has_metadata = True
              
              # Count unique values
              unique_platforms = list(set(platforms))
              unique_entity_types = list(set(entity_types))
              processed_entities = len(entities) - skipped_entities
              
              print(f"ğŸ“Š Analysis Results:")
              print(f"   Total Entities: {len(entities)}")
              print(f"   Processed Entities: {processed_entities}")
              print(f"   Skipped Entities: {skipped_entities}")
              print(f"   Platforms: {', '.join(unique_platforms) if unique_platforms else 'None'}")
              print(f"   Entity Types: {', '.join(unique_entity_types) if unique_entity_types else 'None'}")
              print(f"   Has Metadata: {has_metadata}")
              
              # Set GitHub outputs
              with open('$GITHUB_OUTPUT', 'a') as f:
                  f.write(f"platforms={','.join(unique_platforms)}\n")
                  f.write(f"entity_types={','.join(unique_entity_types)}\n")
                  f.write(f"entity_count={processed_entities}\n")
                  f.write(f"has_mutations={'true' if has_metadata else 'false'}\n")
              
          except Exception as e:
              print(f"âŒ Failed to analyze entities: {e}")
              sys.exit(1)
          EOF

  migrate-metadata:
    runs-on: ubuntu-latest
    needs: [validate-inputs, analyze-entities]
    if: needs.analyze-entities.outputs.has_mutations == 'true'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-web.txt

      - name: Create output directory
        run: |
          mkdir -p metadata-migration/output
          mkdir -p metadata-migration/logs

      - name: Run metadata migration (Dry Run)
        if: ${{ github.event.inputs.dry_run == 'true' }}
        run: |
          echo "ğŸ§ª Running metadata migration in DRY RUN mode..."
          echo "â„¹ï¸  Note: Mutations have already been applied during export"
          
          python scripts/process_metadata_migration.py \
            --input "${{ github.event.inputs.entities_file }}" \
            --target-env "${{ github.event.inputs.target_environment }}" \
            --output-dir "metadata-migration/output" \
            --dry-run \
            --verbose > metadata-migration/logs/migration.log 2>&1
          
          echo "ğŸ“‹ Migration summary:"
          tail -20 metadata-migration/logs/migration.log

      - name: Run metadata migration (Live)
        if: ${{ github.event.inputs.dry_run == 'false' }}
        env:
          DATAHUB_GMS_URL: ${{ secrets[format('DATAHUB_GMS_URL_{0}', github.event.inputs.target_environment)] }}
          DATAHUB_GMS_TOKEN: ${{ secrets[format('DATAHUB_GMS_TOKEN_{0}', github.event.inputs.target_environment)] }}
        run: |
          echo "ğŸš€ Running metadata migration in LIVE mode..."
          echo "â„¹ï¸  Note: Mutations have already been applied during export"
          
          python scripts/process_metadata_migration.py \
            --input "${{ github.event.inputs.entities_file }}" \
            --target-env "${{ github.event.inputs.target_environment }}" \
            --verbose > metadata-migration/logs/migration.log 2>&1
          
          echo "ğŸ“‹ Migration summary:"
          tail -20 metadata-migration/logs/migration.log

      - name: Upload migration artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: metadata-migration-${{ github.event.inputs.source_environment }}-to-${{ github.event.inputs.target_environment }}-${{ github.run_number }}
          path: |
            metadata-migration/output/
            metadata-migration/logs/
          retention-days: 30

      - name: Create summary comment
        uses: actions/github-script@v7
        if: always()
        with:
          script: |
            const fs = require('fs');
            
            // Read migration log
            let summary = '## Metadata Migration Summary\n\n';
            summary += `**Migration**: ${{ github.event.inputs.source_environment }} â†’ ${{ github.event.inputs.target_environment }}\n`;
            summary += `**Mode**: ${{ github.event.inputs.dry_run == 'true' && 'ğŸ§ª Dry Run' || 'ğŸš€ Live Migration' }}\n`;
            summary += `**Entities**: ${{ needs.analyze-entities.outputs.entity_count }}\n`;
            summary += `**Platforms**: ${{ needs.analyze-entities.outputs.platforms }}\n`;
            summary += `**Entity Types**: ${{ needs.analyze-entities.outputs.entity_types }}\n\n`;
            
            try {
              const logContent = fs.readFileSync('metadata-migration/logs/migration.log', 'utf8');
              const logLines = logContent.split('\n');
              const summaryLines = logLines.filter(line => 
                line.includes('MIGRATION PROCESSING SUMMARY') || 
                line.includes('Source entities:') ||
                line.includes('Target entities:') ||
                line.includes('Entity matches:') ||
                line.includes('MCPs generated:')
              );
              
              if (summaryLines.length > 0) {
                summary += '### Results\n```\n';
                summary += summaryLines.join('\n');
                summary += '\n```\n';
              }
            } catch (error) {
              summary += 'âš ï¸ Could not read migration log\n';
            }
            
            summary += `\nğŸ“ **Artifacts**: Migration logs and generated MCPs are available in the workflow artifacts.`;
            
            console.log(summary);

  validate-migration:
    runs-on: ubuntu-latest
    needs: [migrate-metadata]
    if: ${{ github.event.inputs.dry_run == 'false' && !failure() }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Validate migration results
        env:
          DATAHUB_GMS_URL: ${{ secrets[format('DATAHUB_GMS_URL_{0}', github.event.inputs.target_environment)] }}
          DATAHUB_GMS_TOKEN: ${{ secrets[format('DATAHUB_GMS_TOKEN_{0}', github.event.inputs.target_environment)] }}
        run: |
          echo "âœ… Validating migration results..."
          
          # Sample a few entities to verify metadata was applied
          python << EOF
          import json
          import random
          from utils.datahub_api import DataHubAPIClient
          
          try:
              # Load original entities
              with open('${{ github.event.inputs.entities_file }}', 'r') as f:
                  data = json.load(f)
              
              if isinstance(data, dict):
                  entities = data.get('entities', data.get('export_data', [data]))
              else:
                  entities = data
              
              # Sample up to 5 entities for validation
              sample_entities = random.sample(entities, min(5, len(entities)))
              
              client = DataHubAPIClient()
              
              print("ğŸ” Validating sample entities:")
              for entity in sample_entities:
                  entity_urn = entity.get('urn', '')
                  entity_name = entity.get('name', 'Unknown')
                  
                  print(f"   ğŸ“Š {entity_name}: {entity_urn}")
                  
                  # This is a placeholder - actual validation would check if metadata was applied
                  # For now, just confirm the entity exists
              
              print("âœ… Migration validation completed")
              
          except Exception as e:
              print(f"âš ï¸  Validation failed: {e}")
              # Don't fail the workflow for validation issues
          EOF

  notify-completion:
    runs-on: ubuntu-latest
    needs: [migrate-metadata]
    if: always()
    steps:
      - name: Notify completion
        run: |
          if [ "${{ needs.migrate-metadata.result }}" = "success" ]; then
            echo "ğŸ‰ Metadata migration completed successfully!"
            echo "Mode: ${{ github.event.inputs.dry_run == 'true' && 'Dry Run' || 'Live Migration' }}"
            echo "Migration: ${{ github.event.inputs.source_environment }} â†’ ${{ github.event.inputs.target_environment }}"
          else
            echo "âŒ Metadata migration failed or was cancelled"
            echo "Check the workflow logs and artifacts for more details"
          fi 