name: Deploy Recipes

on:
  # Run only on main branch
  push:
    branches: [ main ]
    paths:
      - 'recipes/instances/**/*.yml'
  # Manual trigger with options
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod
      deployment_type:
        description: 'What to deploy'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - selected
          - recent
      specific_recipes:
        description: 'Specific recipes to deploy (comma-separated, only for "selected" type)'
        required: false
        type: string
      since_hours:
        description: 'Deploy recipes modified in the last N hours (only for "recent" type)'
        required: false
        default: '24'
        type: number
      create_secrets:
        description: 'Create secrets in DataHub'
        required: false
        default: false
        type: boolean

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Fetch all history for checking recent changes

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Test DataHub Connection
        env:
          DATAHUB_GMS_URL: ${{ secrets.DATAHUB_GMS_URL }}
          DATAHUB_TOKEN: ${{ secrets.DATAHUB_TOKEN }}
        run: |
          echo "Testing connection to DataHub..."
          python -c "
          import os, sys
          from dotenv import load_dotenv
          sys.path.append('utils')
          from datahub_rest_client import DataHubRestClient
          
          # Set environment variables
          os.environ['DATAHUB_GMS_URL'] = '${{ secrets.DATAHUB_GMS_URL }}'
          os.environ['DATAHUB_TOKEN'] = '${{ secrets.DATAHUB_TOKEN }}'
          
          try:
              # Create client
              client = DataHubRestClient(
                  server_url=os.environ['DATAHUB_GMS_URL'],
                  token=os.environ['DATAHUB_TOKEN']
              )
              
              # Test connection
              if client.test_connection():
                  print('✅ Successfully connected to DataHub!')
              else:
                  print('❌ Failed to connect to DataHub')
                  sys.exit(1)
          except Exception as e:
              print(f'❌ Error connecting to DataHub: {str(e)}')
              sys.exit(1)
          "

      - name: Identify recipes to deploy
        id: identify-recipes
        run: |
          ENV="${{ github.event.inputs.environment || 'dev' }}"
          DEPLOYMENT_TYPE="${{ github.event.inputs.deployment_type || 'all' }}"
          SPECIFIC_RECIPES="${{ github.event.inputs.specific_recipes }}"
          SINCE_HOURS="${{ github.event.inputs.since_hours || '24' }}"
          
          echo "Environment: $ENV"
          echo "Deployment type: $DEPLOYMENT_TYPE"
          
          # Generate list of recipes to deploy
          if [ "$DEPLOYMENT_TYPE" = "all" ] || [ "$GITHUB_EVENT_NAME" = "push" ]; then
            # For "all" type or automatic push to main, deploy all recipes
            echo "Deploying all recipes for $ENV environment"
            find "recipes/instances/$ENV" -name "*.yml" > recipes_to_deploy.txt
          elif [ "$DEPLOYMENT_TYPE" = "selected" ] && [ -n "$SPECIFIC_RECIPES" ]; then
            # For "selected" type, deploy specific recipes
            echo "Deploying selected recipes: $SPECIFIC_RECIPES"
            > recipes_to_deploy.txt
            IFS=',' read -ra RECIPES <<< "$SPECIFIC_RECIPES"
            for recipe in "${RECIPES[@]}"; do
              recipe_file="recipes/instances/$ENV/$(echo $recipe | xargs).yml"
              if [ -f "$recipe_file" ]; then
                echo "$recipe_file" >> recipes_to_deploy.txt
              else
                echo "Warning: Recipe not found: $recipe_file"
              fi
            done
          elif [ "$DEPLOYMENT_TYPE" = "recent" ]; then
            # For "recent" type, deploy recipes modified in the last N hours
            echo "Deploying recipes modified in the last $SINCE_HOURS hours"
            find "recipes/instances/$ENV" -name "*.yml" -mtime -$((SINCE_HOURS/24)) > recipes_to_deploy.txt
          fi
          
          # Count recipes
          RECIPE_COUNT=$(wc -l < recipes_to_deploy.txt)
          echo "Found $RECIPE_COUNT recipes to deploy"
          
          if [ "$RECIPE_COUNT" -eq 0 ]; then
            echo "No recipes to deploy"
            exit 0
          fi
          
          # Output recipe count for later steps
          echo "recipe_count=$RECIPE_COUNT" >> $GITHUB_OUTPUT
          
          # Log recipes to deploy
          echo "Recipes to deploy:"
          cat recipes_to_deploy.txt

      - name: Deploy recipes to DataHub
        if: steps.identify-recipes.outputs.recipe_count > 0
        env:
          DATAHUB_GMS_URL: ${{ secrets.DATAHUB_GMS_URL }}
          DATAHUB_TOKEN: ${{ secrets.DATAHUB_TOKEN }}
          # Databricks secrets
          DBX_TOKEN: ${{ secrets.DBX_TOKEN }}
          # SQL Server secrets
          MSSQL_PASSWORD: ${{ secrets.MSSQL_PASSWORD }}
          # Additional database secrets
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          MYSQL_PASSWORD: ${{ secrets.MYSQL_PASSWORD }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          BIGQUERY_KEYFILE: ${{ secrets.BIGQUERY_KEYFILE }}
        run: |
          ENV=${{ github.event.inputs.environment || 'dev' }}
          CREATE_SECRETS="${{ github.event.inputs.create_secrets || 'false' }}"
          
          # Add create-secrets parameter if enabled
          SECRETS_PARAM=""
          if [ "$CREATE_SECRETS" = "true" ]; then
            SECRETS_PARAM="--create-secrets"
            echo "Creating secrets in DataHub is enabled"
          fi
          
          # Read and deploy recipes one by one
          while IFS= read -r recipe; do
            echo "Deploying recipe: $recipe"
            python scripts/push_recipe.py --instance "$recipe" $SECRETS_PARAM
          done < recipes_to_deploy.txt

      - name: Generate deployment report
        if: steps.identify-recipes.outputs.recipe_count > 0
        run: |
          ENV=${{ github.event.inputs.environment || 'dev' }}
          REPORT_FILE="deployment_report_${ENV}_$(date +%Y%m%d_%H%M%S).txt"
          
          echo "DataHub Recipe Deployment Report" > $REPORT_FILE
          echo "Environment: $ENV" >> $REPORT_FILE
          echo "Date: $(date)" >> $REPORT_FILE
          echo "Deployed by: ${{ github.actor }}" >> $REPORT_FILE
          echo "Deployment triggered by: ${{ github.event_name }}" >> $REPORT_FILE
          echo "Created secrets in DataHub: ${{ github.event.inputs.create_secrets || 'false' }}" >> $REPORT_FILE
          echo "" >> $REPORT_FILE
          echo "Deployed Recipes:" >> $REPORT_FILE
          
          cat recipes_to_deploy.txt | while read recipe; do
            recipe_name=$(basename "$recipe" .yml)
            recipe_type=$(grep "recipe_type" "$recipe" | cut -d ":" -f2 | tr -d ' ')
            echo "- $recipe_name (Type: $recipe_type)" >> $REPORT_FILE
          done
          
          echo "" >> $REPORT_FILE
          echo "Deployment Status: Success" >> $REPORT_FILE
          
          # Upload report as artifact
          mkdir -p deployment_reports
          mv $REPORT_FILE deployment_reports/

      - name: Upload deployment report
        if: steps.identify-recipes.outputs.recipe_count > 0
        uses: actions/upload-artifact@v3
        with:
          name: deployment-reports
          path: deployment_reports/
          retention-days: 30